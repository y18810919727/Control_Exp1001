# 中心调度

中心调度模块是仿真模型和控制模型之间进行交互的调度器，用户使用该平台进行控制实验时，在定义完仿真对象、控制对象以及相应组建后即可创建中心调度对象进行实验。该中心调度器具有以下特点：

- 每个中心调度器负责一个实验环境与一个控制器的交互
- 在控制器训练时自动对控制模型进行评估
- 在训练过程中记录控制模型在每个round获得的奖赏值

## 创建中心调度器的方法

```python
def __init__(self, env=None, controller=None,
             max_frame=100000,
             rounds=100,
             max_step=1000,
             eval_rounds=10,
             eval_length=None,
             exp_name=None):
```

- 参数详解:

  - env: 仿真环境
  - controller: 控制模型
  - max_frame: 最大迭代次数
  - rounds: 训练回合数
  - max_step: 每个回合内的最大迭代次数
  - eval_rounds: 评估轮次，强制大于等于1，且必须能够整除rounds。
  - eval_length: 每次评估过程中，迭代次数，默认等于max_step
  - exp_name: 实验名称



  评估过程在模型未训练时就会执行一次，之后每过**eval_cycle**个round就会评估一次

  eval_cycle = rounds / eval_rounds 

  > 注：eval_rounds 必须能够整除rounds

  即：

  第一次评估在 第 0 个round，

  第二次评估在 第 eval_cycle 个round，

  第三次评估在 第 eval_cycle*2 个round，

  最后一次评估在eval_cycle*(eval_rounds-1)个round，

  > 另外，在模型全部训练完成后，会再评估一次，所以实际评估次数时eval_rounds+1

- 举例

  ```python
  from Control_Exp1001.exp.base_exp import BaseExp
  
  exp = BaseExp(
          env=env,
          controller=controller,
          max_frame = 100000,
          rounds= 10,
          max_step=10,
          eval_rounds=5,
          eval_length=None,
          exp_name="td3-exploration_noise=1.1"
      )
  result = exp.run()
  
  ```

result为一个元祖(rewards, eval_list, eval_reward_list):

1. rewards : 一个列表，每个元素代表每个round中获得的奖赏和

2. eval_list：一个列表，每个元素为一次评估结果，表示为一个元祖(y_array, y_star_array)

   - y_array：一个矩阵，shape=[评估过程迭代次数, $y$的维度]，表示本次评估过程中y的实际值

   - y_star_array：一个矩阵，shape=[评估过程迭代次数 , $y^*$的维度]，表示本次评估过程中y的设定值


## 多线程运行

在exp包中，还有一个**exp_perform**模块，用于多线程执行每个实验。

- 举例

```python
from Control_Exp1001.exp.exp_perform import exp_multi_thread_run

exp1 = BaseExp(
        env=env1,
        controller=controller1,
        max_frame = 100000,
        rounds= 10,
        max_step=10,
        eval_rounds=5,
        eval_length=None,
        exp_name="exploration_noise=1.1"
    )

exp2 = BaseExp(
        env=env2,
        controller=controller2,
        max_frame = 100000,
        rounds= 10,
        max_step=10,
        eval_rounds=5,
        eval_length=None,
        exp_name="exploration_noise=1.01"
    )
exp3 = BaseExp(
        env=env3,
        controller=controller3,
        max_frame = 100000,
        rounds= 10,
        max_step=10,
        eval_rounds=5,
        eval_length=None,
        exp_name="best"
    )

# 多线程运行
res_list = exp_multi_thread_run([exp1, exp2, exp3])
```

## 训练过程中控制效果评估

评估过程在模型未训练时就会执行一次，之后每过**eval_cycle**个round就会评估一次

```python
eval_cycle = rounds / eval_rounds 
```

另外，在模型全部训练完成后，会再评估一次，所以实际评估次数时eval_rounds+1。

调用评估函数

```
exp.evaluate(self, t)
```

>  评估过程在run()函数中已经封装好，一般情况下不需要人为调用

之后根据多线程跑出的实验结果，直接调用EvaluationBase模块即可实现评估结果可视化。